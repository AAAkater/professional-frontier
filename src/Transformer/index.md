# Transformer

## 1 架构总览：Encoder 与 Decoder 的协同设计

Transformer 作为序列处理领域的里程碑模型，采用完全基于注意力机制的架构设计，摒弃传统的循环或卷积结构。

### 1.1 Encoder 结构

*   **层级堆叠**：由 N 个完全相同的网络层组成
*   **核心子层**：
    *   多头自注意力机制（Multi-Head Self-Attention）
    *   全连接前馈神经网络（Feed Forward Network）

### 1.2 Decoder 结构
*   **层级堆叠**：同样由 N 个相同网络层组成
*   **核心子层**：
    *   掩码多头自注意力（Masked Multi-Head Self-Attention）
    *   编码器-解码器注意力（处理 Encoder 输出）
    *   全连接前馈神经网络
*   **优化技术**：
    *   残差连接（Residual Connection）
    *   层归一化（Layer Normalization）

> 设计优势：  
> • 捕获序列位置间复杂依赖关系  
> • 支持并行计算，显著提高训练效率
![1.png](https://img.picui.cn/free/2025/06/21/6856b6d58a16e.png)
## 2 核心组件：注意力机制详解

### 2.1 Scaled Dot-Product Attention
实现"自注意力"（Self-Attention）的基础单元：

1.  **线性变换**：输入序列 → Q(Query)/K(Key)/V(Value)
2.  **相似度计算**：Q·K → 原始注意力得分
3.  **尺度缩放**：得分 ÷ √d_k（防止梯度消失）
4.  **掩码操作**（Decoder专用）：屏蔽未来位置信息
5.  **Softmax归一化**：得分 → 概率分布
6.  **加权聚合**：概率权重 × V → 输出

> 核心价值：自适应关注输入序列相关部分，有效捕捉长距离依赖
![2.png](https://img.picui.cn/free/2025/06/21/6856b6d525895.png)

### 2.2 Multi-Head Attention
Scaled Dot-Product Attention 的增强扩展：

1.  **多头投影**：
    *   Q/K/V 分割到 h 个低维子空间
    *   投影维度：d_k = d_model/h
2.  **并行计算**：
    *   每个头独立应用 Scaled Dot-Product
    *   生成 h 个独立输出
3.  **结果融合**：
    *   拼接 (Concat) h 个输出
    *   线性变换 → 最终结果

> 核心优势：  
> • 同时关注不同语义子空间  
> • 捕获更丰富的表示关系
![3.png](https://img.picui.cn/free/2025/06/21/6856b6d5779bc.png)

## 3 残差连接与层归一化：优化深度网络的关键
各子层统一采用：

*   **残差连接**：`输出 = x + F(x)`  
    → 确保梯度有效传播，缓解梯度消失
*   **层归一化**：特征维度归一化  
    → 稳定训练过程，加速收敛

> 技术效果：  
> • 支持训练 100+ 层深度网络  
> • 保持强大表达能力与计算效率

## 4 计算效率与可扩展性
注意力机制复杂度 O(n²)，长序列处理优化方案：

*   **稀疏注意力机制**：
    - 限制位置关注范围
    - 显著降低计算复杂度
*   **近似注意力算法**：
    - Linformer：低秩近似技术
    - Reformer：局部敏感哈希加速
*   **内存优化技术**：
    - 分块计算
    - 梯度检查点

> 改进效果：  
> 使Transformer能够处理更长序列，扩展应用场景边界

## 5 应用与演进：从 NLP 到多模态

### 5.1 NLP 领域的革命性模型
*   **Encoder 架构**：
    - BERT：双向预训练语言模型
    - 特点：全面捕捉上下文语义
*   **Decoder 架构**：
    - GPT 系列：自回归语言模型
    - 特点：强大的文本生成能力
*   **完整架构**：
    - T5：统一编码器-解码器框架
    - 特点：多任务统一建模

### 5.2 跨模态扩展应用
*   **计算机视觉**：
    - ViT（Vision Transformer）
    - Swin Transformer
*   **语音处理**：
    - Conformer
*   **通用框架**：
    - 注意力机制成为深度学习标准组件
    - 支撑多模态融合研究